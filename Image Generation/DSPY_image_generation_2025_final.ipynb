{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install dspy-ai pandas"
      ],
      "metadata": {
        "id": "VQGyPRMLhUya",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f84cd62c-6296-4a2c-e2e2-dc12c4d67029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dspy-ai\n",
            "  Downloading dspy_ai-3.0.3-py3-none-any.whl.metadata (285 bytes)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Collecting dspy>=3.0.3 (from dspy-ai)\n",
            "  Downloading dspy-3.0.3-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Collecting backoff>=2.2 (from dspy>=3.0.3->dspy-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: joblib~=1.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (1.5.2)\n",
            "Requirement already satisfied: openai>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (1.109.1)\n",
            "Requirement already satisfied: regex>=2023.10.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (2024.11.6)\n",
            "Requirement already satisfied: orjson>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (3.11.3)\n",
            "Requirement already satisfied: tqdm>=4.66.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (2.32.4)\n",
            "Collecting optuna>=3.4.0 (from dspy>=3.0.3->dspy-ai)\n",
            "  Downloading optuna-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (2.11.10)\n",
            "Collecting magicattr>=0.1.6 (from dspy>=3.0.3->dspy-ai)\n",
            "  Downloading magicattr-0.1.6-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting litellm>=1.64.0 (from dspy>=3.0.3->dspy-ai)\n",
            "  Downloading litellm-1.78.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m610.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting diskcache>=5.6.0 (from dspy>=3.0.3->dspy-ai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting json-repair>=0.30.0 (from dspy>=3.0.3->dspy-ai)\n",
            "  Downloading json_repair-0.52.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (8.5.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (4.11.0)\n",
            "Collecting asyncer==0.0.8 (from dspy>=3.0.3->dspy-ai)\n",
            "  Downloading asyncer-0.0.8-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools>=5.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (5.5.2)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (3.1.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (13.9.4)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from dspy>=3.0.3->dspy-ai) (3.6.0)\n",
            "Collecting gepa==0.0.7 (from gepa[dspy]==0.0.7->dspy>=3.0.3->dspy-ai)\n",
            "  Downloading gepa-0.0.7-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.3->dspy-ai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.3->dspy-ai) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->dspy>=3.0.3->dspy-ai) (4.15.0)\n",
            "Requirement already satisfied: aiohttp>=3.10 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (3.13.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (8.3.0)\n",
            "Collecting fastuuid>=0.13.0 (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai)\n",
            "  Downloading fastuuid-0.13.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (8.7.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (4.25.1)\n",
            "Requirement already satisfied: python-dotenv>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (1.1.1)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (0.12.0)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (from litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (0.22.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.3->dspy-ai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai>=0.28.1->dspy>=3.0.3->dspy-ai) (0.11.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.3->dspy-ai) (1.17.0)\n",
            "Collecting colorlog (from optuna>=3.4.0->dspy>=3.0.3->dspy-ai)\n",
            "  Downloading colorlog-6.10.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.3->dspy-ai) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.3->dspy-ai) (2.0.44)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna>=3.4.0->dspy>=3.0.3->dspy-ai) (6.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.3->dspy-ai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.3->dspy-ai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.0->dspy>=3.0.3->dspy-ai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.3->dspy-ai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.3->dspy-ai) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31.0->dspy>=3.0.3->dspy-ai) (2025.10.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.3->dspy-ai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.7.1->dspy>=3.0.3->dspy-ai) (2.19.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp>=3.10->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (1.22.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna>=3.4.0->dspy>=3.0.3->dspy-ai) (1.3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (0.16.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=6.8.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (0.27.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->dspy>=3.0.3->dspy-ai) (0.1.2)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna>=3.4.0->dspy>=3.0.3->dspy-ai) (3.2.4)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (0.35.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers->litellm>=1.64.0->dspy>=3.0.3->dspy-ai) (1.1.10)\n",
            "Downloading dspy_ai-3.0.3-py3-none-any.whl (1.1 kB)\n",
            "Downloading dspy-3.0.3-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.7/261.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asyncer-0.0.8-py3-none-any.whl (9.2 kB)\n",
            "Downloading gepa-0.0.7-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.52.1-py3-none-any.whl (26 kB)\n",
            "Downloading litellm-1.78.5-py3-none-any.whl (9.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading magicattr-0.1.6-py2.py3-none-any.whl (4.7 kB)\n",
            "Downloading optuna-4.5.0-py3-none-any.whl (400 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastuuid-0.13.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.3/272.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.10.1-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: magicattr, json-repair, gepa, fastuuid, diskcache, colorlog, backoff, asyncer, optuna, litellm, dspy, dspy-ai\n",
            "Successfully installed asyncer-0.0.8 backoff-2.2.1 colorlog-6.10.1 diskcache-5.6.3 dspy-3.0.3 dspy-ai-3.0.3 fastuuid-0.13.5 gepa-0.0.7 json-repair-0.52.1 litellm-1.78.5 magicattr-0.1.6 optuna-4.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv openai"
      ],
      "metadata": {
        "id": "-pY5doXThiMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "3b4db304-a4b1-4fa8-a4e6-239e8201238e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.109.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.11.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set environment variables directly in Colab\n",
        "import os\n",
        "os.environ['OPENROUTER_API_KEY'] = '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'\n",
        "os.environ['MODEL'] = 'z-ai/glm-4.5-air:free'\n",
        "os.environ['TEMPERATURE'] = '0.7'"
      ],
      "metadata": {
        "id": "eREQJEaChm5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Set environment variables directly in Colab\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Ask for OpenRouter API key securely\n",
        "api_key = getpass('Enter your OpenRouter API key: ')\n",
        "\n",
        "os.environ['OPENROUTER_API_KEY'] = api_key\n",
        "os.environ['MODEL'] = 'z-ai/glm-4.5-air:free'\n",
        "os.environ['TEMPERATURE'] = '0.3'\n",
        "\n",
        "# Also save to .env file for persistence\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(f\"OPENROUTER_API_KEY={api_key}\\n\")\n",
        "    f.write(f\"MODEL=z-ai/glm-4.5-air:free\\n\")\n",
        "    f.write(f\"TEMPERATURE=0.3\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NVUYl5WQuRp",
        "outputId": "240c095c-6d9e-46d5-c91b-445ec2467dc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenRouter API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Their are 2 methods. The below cell uses \"Chain of Thought\" and other cell below it uses \"Predict\". The first one is more sophisticted. play with temperature change."
      ],
      "metadata": {
        "id": "wA-uBMLy7Y17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import logging\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('/content/.env')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Import required libraries\n",
        "import dspy\n",
        "from dspy import Example, Predict, ChainOfThought\n",
        "\n",
        "# API configuration\n",
        "API_KEY = os.getenv(\"OPENROUTER_API_KEY\") or \"\"\n",
        "MODEL = \"z-ai/glm-4.5-air:free\"\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "# Check if API key is available\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"OPENROUTER_API_KEY not found in environment variables\")\n",
        "\n",
        "# Set up DSPy to use GLM via OpenRouter\n",
        "lm = dspy.LM(\n",
        "    model=\"openai/\" + MODEL,\n",
        "    api_key=API_KEY,\n",
        "    temperature=TEMPERATURE,\n",
        "    base_url=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "dspy.settings.configure(lm=lm)\n",
        "logger.info(f\"Successfully configured DSPy with {MODEL}\")\n",
        "\n",
        "# Import validation functions\n",
        "def validate_taste(taste: str) -> str:\n",
        "    \"\"\"Validate the artistic taste category.\"\"\"\n",
        "    valid_tastes = ['photorealistic', 'oil painting', 'anime', 'cyberpunk', 'watercolor', '3d render', 'flat illustration']\n",
        "    if taste.lower() not in valid_tastes:\n",
        "        raise ValueError(f\"Invalid taste. Choose from: {', '.join(valid_tastes)}\")\n",
        "    return taste.lower()\n",
        "\n",
        "def validate_input(user_input: str) -> str:\n",
        "    \"\"\"Validate the user input description.\"\"\"\n",
        "    if not user_input or len(user_input.strip()) < 3:\n",
        "        raise ValueError(\"Please provide a description (at least 3 characters)\")\n",
        "    return user_input.strip()\n",
        "\n",
        "# Define DSPy signatures\n",
        "class InitialPromptOptimization(dspy.Signature):\n",
        "    \"\"\"Optimize user input into a detailed image prompt for the specified artistic style.\"\"\"\n",
        "    taste = dspy.InputField(desc=\"Artistic style (e.g., photorealistic, anime)\")\n",
        "    user_input = dspy.InputField(desc=\"Simple user description\")\n",
        "    optimized_prompt = dspy.OutputField(desc=\"Detailed optimized prompt\")\n",
        "    reasoning = dspy.OutputField(desc=\"Step-by-step reasoning for the optimization\")\n",
        "\n",
        "class PromptEnhancement(dspy.Signature):\n",
        "    \"\"\"Enhance an optimized prompt with technical details and artistic refinements.\"\"\"\n",
        "    base_prompt = dspy.InputField(desc=\"Already optimized prompt\")\n",
        "    taste = dspy.InputField(desc=\"Artistic style\")\n",
        "    enhanced_prompt = dspy.OutputField(desc=\"Enhanced prompt with technical details and artistic refinements\")\n",
        "    reasoning = dspy.OutputField(desc=\"Step-by-step reasoning for the enhancement\")\n",
        "\n",
        "# Define DSPy modules\n",
        "class InitialPromptOptimizer(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Changed from Predict to ChainOfThought\n",
        "        self.optimize = ChainOfThought(InitialPromptOptimization)\n",
        "\n",
        "    def forward(self, taste: str, user_input: str):\n",
        "        return self.optimize(taste=taste, user_input=user_input)\n",
        "\n",
        "class PromptEnhancer(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Changed from Predict to ChainOfThought\n",
        "        self.enhance = ChainOfThought(PromptEnhancement)\n",
        "\n",
        "    def forward(self, base_prompt: str, taste: str):\n",
        "        return self.enhance(base_prompt=base_prompt, taste=taste)\n",
        "\n",
        "class FullPromptOptimizer(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.initial_optimizer = InitialPromptOptimizer()\n",
        "        self.enhancer = PromptEnhancer()\n",
        "\n",
        "    def forward(self, taste: str, user_input: str):\n",
        "        # Step 1: Initial prompt optimization\n",
        "        optimized_result = self.initial_optimizer(taste=taste, user_input=user_input)\n",
        "\n",
        "        # Step 2: Enhance the optimized prompt\n",
        "        enhanced_result = self.enhancer(\n",
        "            base_prompt=optimized_result.optimized_prompt,\n",
        "            taste=taste\n",
        "        )\n",
        "\n",
        "        # Return the results as attributes of a simple object\n",
        "        # Note: ChainOfThought returns 'reasoning' not 'optimized_reasoning' and 'enhanced_reasoning'\n",
        "        class OptimizationResult:\n",
        "            def __init__(self, optimized_prompt, reasoning, enhanced_prompt, enhanced_reasoning):\n",
        "                self.optimized_prompt = optimized_prompt\n",
        "                self.reasoning = reasoning\n",
        "                self.enhanced_prompt = enhanced_prompt\n",
        "                self.enhanced_reasoning = enhanced_reasoning\n",
        "\n",
        "        return OptimizationResult(\n",
        "            optimized_prompt=optimized_result.optimized_prompt,\n",
        "            reasoning=optimized_result.reasoning,\n",
        "            enhanced_prompt=enhanced_result.enhanced_prompt,\n",
        "            enhanced_reasoning=enhanced_result.reasoning\n",
        "        )\n",
        "\n",
        "# Prepare training data\n",
        "def create_training_data() -> List[Dict[str, str]]:\n",
        "    \"\"\"Create training examples for DSPy.\"\"\"\n",
        "    return [\n",
        "        {\n",
        "            'taste': 'photorealistic',\n",
        "            'user_input': 'a cat sitting on a windowsill',\n",
        "            'optimized_prompt': 'Ultra realistic photograph of a ginger cat sitting on a sunlit windowsill, detailed fur texture, sharp focus, natural lighting, 85mm lens, shallow depth of field',\n",
        "            'optimized_reasoning': 'The original description is simple. I enhanced it by adding details about the cat\\'s color, the lighting conditions, camera equipment, and photography techniques.',\n",
        "            'enhanced_prompt': 'Ultra realistic photograph of a ginger cat sitting on a sunlit windowsill, detailed fur texture, sharp focus, natural lighting, 85mm lens, shallow depth of field, 4K resolution, f/1.8 aperture, golden hour glow, cinematic composition',\n",
        "            'enhanced_reasoning': 'I added technical photography details like resolution, aperture, and lighting to make the prompt more specific for photorealistic rendering.'\n",
        "        },\n",
        "        {\n",
        "            'taste': 'oil painting',\n",
        "            'user_input': 'a mountain landscape',\n",
        "            'optimized_prompt': 'Oil painting of majestic mountain landscape at sunset, impressionist style, visible brushstrokes, warm golden hour light, textured canvas, rich color palette',\n",
        "            'optimized_reasoning': 'I enhanced the basic mountain landscape by specifying it as an oil painting in impressionist style, with details about brushwork and lighting.',\n",
        "            'enhanced_prompt': 'Oil painting of majestic mountain landscape at sunset, impressionist style, visible brushstrokes, warm golden hour light, textured canvas, rich color palette, canvas texture visible, Rembrandt lighting, thick impasto technique, 24\"x36\" aspect ratio',\n",
        "            'enhanced_reasoning': 'I added oil painting specific techniques like impasto, canvas texture, and referenced Rembrandt lighting to enhance the artistic quality.'\n",
        "        },\n",
        "        {\n",
        "            'taste': 'anime',\n",
        "            'user_input': 'a futuristic city',\n",
        "            'optimized_prompt': 'Anime style illustration of a futuristic cyberpunk cityscape at night, neon lights, flying vehicles, detailed architecture, vibrant colors, high contrast',\n",
        "            'optimized_reasoning': 'I took the basic futuristic city concept and transformed it into an anime-style cyberpunk city with specific visual elements.',\n",
        "            'enhanced_prompt': 'Anime style illustration of a futuristic cyberpunk cityscape at night, neon lights, flying vehicles, detailed architecture, vibrant colors, high contrast, Studio Ghibli influences, detailed backgrounds, cel-shaded rendering, 1080p resolution',\n",
        "            'enhanced_reasoning': 'I added anime-specific rendering techniques like cel-shading, referenced Studio Ghibli style, and included resolution details.'\n",
        "        },\n",
        "        {\n",
        "            'taste': 'cyberpunk',\n",
        "            'user_input': 'a street market',\n",
        "            'optimized_prompt': 'Cyberpunk street market at night, neon signs, diverse crowd, stalls selling futuristic tech, rain-slicked streets, Blade Runner aesthetic',\n",
        "            'optimized_reasoning': 'I enhanced the basic street market with cyberpunk elements like neon lighting, futuristic technology, and rain-slicked streets.',\n",
        "            'enhanced_prompt': 'Cyberpunk street market at night, neon signs, diverse crowd, stalls selling futuristic tech, rain-slicked streets, Blade Runner aesthetic, cinematic lighting, volumetric fog, reflections on wet pavement, ultra-detailed, 8K resolution',\n",
        "            'enhanced_reasoning': 'I added cinematic elements like volumetric fog and reflections, and included technical details like 8K resolution for higher quality rendering.'\n",
        "        },\n",
        "        {\n",
        "            'taste': 'watercolor',\n",
        "            'user_input': 'a flower garden',\n",
        "            'optimized_prompt': 'Watercolor painting of a vibrant flower garden, soft washes, fluid color transitions, transparent layers, loose brushwork',\n",
        "            'optimized_reasoning': 'I enhanced the basic flower garden description by specifying watercolor techniques like washes and transparent layers.',\n",
        "            'enhanced_prompt': 'Watercolor painting of a vibrant flower garden, soft washes, fluid color transitions, transparent layers, loose brushwork, wet-on-wet technique, visible paper texture, subtle bleeding of colors, delicate edges, pastel color palette, light and airy atmosphere',\n",
        "            'enhanced_reasoning': 'I added specific watercolor techniques like wet-on-wet and references to the characteristic transparency and bleeding effects of watercolor painting.'\n",
        "        },\n",
        "        {\n",
        "            'taste': '3d render',\n",
        "            'user_input': 'a futuristic car',\n",
        "            'optimized_prompt': '3D render of a futuristic car, sleek design, metallic surfaces, detailed model, clean lines',\n",
        "            'optimized_reasoning': 'I transformed the basic car description into a 3D render by specifying modeling details and surface characteristics.',\n",
        "            'enhanced_prompt': '3D render of a futuristic car, sleek design, metallic surfaces, detailed model, clean lines, UV mapping, polygonal structure, PBR materials, subsurface scattering, specular highlights, studio lighting, octane render, 8K resolution, detailed interior, aerodynamic details',\n",
        "            'enhanced_reasoning': 'I added 3D-specific technical details like UV mapping, polygonal structure, and rendering engine specifications to create a professional 3D render.'\n",
        "        },\n",
        "        {\n",
        "            'taste': 'flat illustration',\n",
        "            'user_input': 'a civil engineer working on construction projects',\n",
        "            'optimized_prompt': 'Flat illustration of a civil engineer working on construction projects for quality audit of high-rise towers, soft color palette, clean lines, contemporary art style',\n",
        "            'optimized_reasoning': 'I enhanced the basic description by specifying it as a flat illustration with a clean, contemporary style and soft colors to match the aesthetic.',\n",
        "            'enhanced_prompt': 'Flat illustration of a civil engineer working on construction projects for quality audit of high-rise towers, soft color palette, a poster by Tom Whalen, featured on behance, context art, behance hd, art on instagram, storybook illustration, Pro freelance, Illustration agency, Popular on Dribbble, soft shadows, no contrast, clean ultrasharp focus, premium vector, hand drawn people, timeless art, human illustration, freepik, flat colours, their faces are visible, show less details, clean lines and smooth curves, 2d flat illustration, contemporary art illustration, contemporary painting, use minimum props, limited Colors, use light grey color overlay for shadow, use light white color overlay for highlights, delicate art, whimsy and wonder, whimsical, by Alice Lee style, Wax crayon brushes procreate style, hand drawn',\n",
        "            'enhanced_reasoning': 'I added specific flat illustration techniques and references to artists known for this style, along with details about color palettes, line work, and digital tools used to create this aesthetic.'\n",
        "        }\n",
        "    ]\n",
        "\n",
        "# Simple data container\n",
        "class TrainingData:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return Example(\n",
        "            taste=item['taste'],\n",
        "            user_input=item['user_input'],\n",
        "            optimized_prompt=item['optimized_prompt'],\n",
        "            optimized_reasoning=item['optimized_reasoning'],\n",
        "            enhanced_prompt=item['enhanced_prompt'],\n",
        "            enhanced_reasoning=item['enhanced_reasoning']\n",
        "        ).with_inputs('taste', 'user_input')\n",
        "\n",
        "# Quality metric for DSPy evaluation\n",
        "def prompt_quality_metric(example, pred, trace=None) -> float:\n",
        "    \"\"\"Calculate quality score for the final enhanced prompt.\"\"\"\n",
        "    prompt = pred.enhanced_prompt\n",
        "\n",
        "    # Quality indicators\n",
        "    has_details = 'detailed' in prompt.lower()\n",
        "    has_style = any(style in prompt.lower() for style in ['style', 'technique', 'aesthetic'])\n",
        "    has_technical = any(tech in prompt.lower() for tech in ['lighting', 'focus', 'texture', 'composition', 'resolution', 'aperture'])\n",
        "    has_mood = any(mood in prompt.lower() for mood in ['mood', 'atmosphere', 'ambiance', 'feeling'])\n",
        "\n",
        "    # Check if it includes relevant technical details for the style\n",
        "    has_photography_terms = True\n",
        "    has_painting_terms = True\n",
        "    has_anime_terms = True\n",
        "    has_cyberpunk_terms = True\n",
        "    has_watercolor_terms = True\n",
        "    has_3d_terms = True\n",
        "    has_flat_illustration_terms = True\n",
        "\n",
        "    if example.taste == 'photorealistic':\n",
        "        has_photography_terms = any(term in prompt.lower() for term in ['aperture', 'f/', 'shutter', 'depth', 'bokeh', 'photography', 'lens', 'camera'])\n",
        "    elif example.taste == 'oil painting':\n",
        "        has_painting_terms = any(term in prompt.lower() for term in ['brushstroke', 'impasto', 'canvas', 'palette', 'texture', 'oil', 'painting', 'brush'])\n",
        "    elif example.taste == 'anime':\n",
        "        has_anime_terms = any(term in prompt.lower() for term in ['anime', 'cel-shaded', 'manga', 'studio ghibli', 'japanese', 'cartoon', 'illustration'])\n",
        "    elif example.taste == 'cyberpunk':\n",
        "        has_cyberpunk_terms = any(term in prompt.lower() for term in ['neon', 'futuristic', 'blade runner', 'rain-slicked', 'volumetric fog', 'cybernetic', 'high-tech'])\n",
        "    elif example.taste == 'watercolor':\n",
        "        has_watercolor_terms = any(term in prompt.lower() for term in ['wet-on-wet', 'washes', 'transparency', 'flow', 'watercolor', 'aqueous', 'bleed'])\n",
        "    elif example.taste == '3d render':\n",
        "        has_3d_terms = any(term in prompt.lower() for term in ['3d', 'render', 'polygon', 'model', 'uv mapping', 'wireframe', 'mesh', 'texture', 'blender', 'maya'])\n",
        "    elif example.taste == 'flat illustration':\n",
        "        has_flat_illustration_terms = any(term in prompt.lower() for term in [\n",
        "            'flat illustration', 'flat colors', 'flat design', 'flat vector', '2d flat',\n",
        "            'clean lines', 'smooth curves', 'soft shadows', 'no contrast', 'clean ultrasharp focus',\n",
        "            'limited colors', 'light grey overlay', 'light white overlay', 'delicate art',\n",
        "            'whimsy', 'whimsical', 'hand drawn', 'procreate', 'wax crayon', 'storybook'\n",
        "        ])\n",
        "\n",
        "    # Calculate score\n",
        "    style_specific_indicators = []\n",
        "\n",
        "    if example.taste == 'photorealistic':\n",
        "        style_specific_indicators = [has_photography_terms]\n",
        "    elif example.taste == 'oil painting':\n",
        "        style_specific_indicators = [has_painting_terms]\n",
        "    elif example.taste == 'anime':\n",
        "        style_specific_indicators = [has_anime_terms]\n",
        "    elif example.taste == 'cyberpunk':\n",
        "        style_specific_indicators = [has_cyberpunk_terms]\n",
        "    elif example.taste == 'watercolor':\n",
        "        style_specific_indicators = [has_watercolor_terms]\n",
        "    elif example.taste == '3d render':\n",
        "        style_specific_indicators = [has_3d_terms]\n",
        "    elif example.taste == 'flat illustration':\n",
        "        style_specific_indicators = [has_flat_illustration_terms]\n",
        "\n",
        "    # Combine general indicators with style-specific ones\n",
        "    indicators = [has_details, has_style, has_technical, has_mood] + style_specific_indicators\n",
        "    return sum(indicators) / len(indicators)\n",
        "\n",
        "# Main DSPy-powered prompt generator\n",
        "class DSPyPromptGenerator:\n",
        "    def __init__(self):\n",
        "        # Create training data\n",
        "        self.trainset = TrainingData(create_training_data())\n",
        "\n",
        "        # Initialize the full optimizer\n",
        "        self.optimizer = FullPromptOptimizer()\n",
        "\n",
        "        # Try to use BootstrapFewShot if available\n",
        "        try:\n",
        "            from dspy.teleprompter import BootstrapFewShot\n",
        "            teleprompter = BootstrapFewShot(metric=prompt_quality_metric)\n",
        "            self.compiled_optimizer = teleprompter.compile(self.optimizer, trainset=self.trainset)\n",
        "            logger.info(\"Using compiled optimizer with BootstrapFewShot\")\n",
        "        except ImportError:\n",
        "            try:\n",
        "                from dspy.teleprompters import BootstrapFewShot\n",
        "                teleprompter = BootstrapFewShot(metric=prompt_quality_metric)\n",
        "                self.compiled_optimizer = teleprompter.compile(self.optimizer, trainset=self.trainset)\n",
        "                logger.info(\"Using compiled optimizer with BootstrapFewShot\")\n",
        "            except ImportError:\n",
        "                logger.warning(\"Could not import BootstrapFewShot from teleprompter module\")\n",
        "                logger.info(\"Using non-compiled optimizer instead\")\n",
        "                self.compiled_optimizer = self.optimizer\n",
        "\n",
        "        self.results = []\n",
        "\n",
        "    def generate(self, taste: str, user_input: str) -> str:\n",
        "      \"\"\"Generate an enhanced image prompt using DSPy-optimized modules.\"\"\"\n",
        "      try:\n",
        "          # Validate inputs\n",
        "          taste = validate_taste(taste)\n",
        "          user_input = validate_input(user_input)\n",
        "          logger.info(f\"Validated input: {taste} - {user_input}\")\n",
        "\n",
        "          # Use the compiled DSPy optimizer or fallback\n",
        "          logger.info(\"Running DSPy-optimized prompt generation...\")\n",
        "          result = self.compiled_optimizer(taste=taste, user_input=user_input)\n",
        "\n",
        "          optimized_prompt = result.optimized_prompt\n",
        "          optimized_reasoning = result.reasoning  # This exists in ChainOfThought\n",
        "          final_prompt = result.enhanced_prompt\n",
        "          final_reasoning = result.enhanced_reasoning  # This exists in ChainOfThought\n",
        "\n",
        "          # Calculate quality score\n",
        "          # Create a simple object with the enhanced prompt for the metric function\n",
        "          class SimplePrediction:\n",
        "              def __init__(self, enhanced_prompt):\n",
        "                  self.enhanced_prompt = enhanced_prompt\n",
        "\n",
        "          quality_score = prompt_quality_metric(\n",
        "              Example(taste=taste, user_input=user_input),\n",
        "              SimplePrediction(final_prompt)\n",
        "          )\n",
        "\n",
        "          # Store result\n",
        "          self.results.append({\n",
        "              'taste': taste,\n",
        "              'user_input': user_input,\n",
        "              'optimized_prompt': optimized_prompt,\n",
        "              'optimized_reasoning': optimized_reasoning,\n",
        "              'final_prompt': final_prompt,\n",
        "              'final_reasoning': final_reasoning,\n",
        "              'quality_score': quality_score\n",
        "          })\n",
        "\n",
        "          logger.info(f\"Generated prompt with quality score: {quality_score:.2f}\")\n",
        "          logger.info(f\"Optimization reasoning: {optimized_reasoning}\")\n",
        "          logger.info(f\"Enhancement reasoning: {final_reasoning}\")\n",
        "          return final_prompt\n",
        "\n",
        "      except Exception as e:\n",
        "          logger.error(f\"Error in prompt generation: {e}\")\n",
        "          fallback_prompt = f\"{taste} style image of {user_input}, detailed, high quality\"\n",
        "          logger.info(f\"Using fallback prompt: {fallback_prompt}\")\n",
        "\n",
        "          # Also store fallback result\n",
        "          self.results.append({\n",
        "              'taste': taste,\n",
        "              'user_input': user_input,\n",
        "              'optimized_prompt': fallback_prompt,\n",
        "              'optimized_reasoning': 'Fallback due to error',\n",
        "              'final_prompt': fallback_prompt,\n",
        "              'final_reasoning': 'Fallback due to error',\n",
        "              'quality_score': 0.0\n",
        "          })\n",
        "\n",
        "          return fallback_prompt\n",
        "\n",
        "    def get_results(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Get all generated results.\"\"\"\n",
        "        return self.results\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function using actual DSPy.\"\"\"\n",
        "    print(\"=== DSPy-Optimized Image Prompt Generation System ===\\n\")\n",
        "    print(\"Using DSPy with:\")\n",
        "    print(\"1. Defined signatures for initial optimization and enhancement\")\n",
        "    print(\"2. Multi-stage pipeline (Initial Optimizer → Enhancer)\")\n",
        "    print(\"3. Chain-of-Thought reasoning for both optimization steps\")\n",
        "\n",
        "    try:\n",
        "        from dspy.teleprompter import BootstrapFewShot\n",
        "        print(\"4. BootstrapFewShot for automatic prompt optimization\")\n",
        "    except ImportError:\n",
        "        try:\n",
        "            from dspy.teleprompters import BootstrapFewShot\n",
        "            print(\"4. BootstrapFewShot for automatic prompt optimization\")\n",
        "        except ImportError:\n",
        "            print(\"4. Basic prompt optimization (teleprompter module not available)\")\n",
        "\n",
        "    print(\"5. Quality-based metrics for evaluation\")\n",
        "    print(f\"6. GLM-4.5-Air as the backend language model\\n\")\n",
        "\n",
        "    # Test examples\n",
        "    examples = [\n",
        "        {\n",
        "            \"taste\": \"flat illustration\",\n",
        "            \"user_input\": \"\"\" A oversized engineer using magnifying glass doing inspection of building construction site under construction buildings signages equipment cranes, soft color palette, a poster by Tom Whalen, featured on behance, context art, behance hd, art on instagram, storybook illustration, Pro freelance, Illustration agency, Popular on Dribbble, soft shadows, no contrast, clean ultrasharp focus, premium vector, hand drawn people, timeless art, human illustration, freepik, flat colours, their faces are visible, show less details, clean lines and smooth curves, 2d flat illustration, contemporary art illustration, contemporary painting, use minimum props, limited Colors, use light grey color overlay for shadow, use light white color overlay for highlights, delicate art, whimsy and wonder, whimsical, by Alice Lee style, Wax crayon brushes procreate style, hand drawn \"\"\"        }\n",
        "    ]\n",
        "\n",
        "    # Initialize the DSPy prompt generator\n",
        "    generator = DSPyPromptGenerator()\n",
        "\n",
        "    for i, example in enumerate(examples, 1):\n",
        "        print(f\"Example {i}:\")\n",
        "        print(f\"Taste: {example['taste']}\")\n",
        "        print(f\"User Input: {example['user_input']}\")\n",
        "\n",
        "        try:\n",
        "            # Generate using DSPy\n",
        "            result = generator.generate(\n",
        "                taste=example['taste'],\n",
        "                user_input=example['user_input']\n",
        "            )\n",
        "\n",
        "            print(f\"\\nDSPy-Optimized Prompt:\")\n",
        "            print(f\"{generator.results[-1]['optimized_prompt']}\")\n",
        "\n",
        "            print(f\"\\nOptimization Reasoning:\")\n",
        "            print(f\"{generator.results[-1]['optimized_reasoning']}\")\n",
        "\n",
        "            print(f\"\\nDSPy-Enhanced Prompt (Final Output):\")\n",
        "            print(f\"{result}\")\n",
        "\n",
        "            print(f\"\\nEnhancement Reasoning:\")\n",
        "            print(f\"{generator.results[-1]['final_reasoning']}\")\n",
        "\n",
        "            print(f\"\\nQuality Score: {generator.results[-1]['quality_score']:.2f}\")\n",
        "            print(\"✅ SUCCESS: DSPy-optimized prompt generation completed!\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ FAILED: {e}\\n\")\n",
        "\n",
        "        print(\"=\"*70)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3m1FR7GD3ZYY",
        "outputId": "c00ae1d5-aacc-49dc-9d57-7344a94ad7c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Could not import BootstrapFewShot from teleprompter module\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DSPy-Optimized Image Prompt Generation System ===\n",
            "\n",
            "Using DSPy with:\n",
            "1. Defined signatures for initial optimization and enhancement\n",
            "2. Multi-stage pipeline (Initial Optimizer → Enhancer)\n",
            "3. Chain-of-Thought reasoning for both optimization steps\n",
            "4. Basic prompt optimization (teleprompter module not available)\n",
            "5. Quality-based metrics for evaluation\n",
            "6. GLM-4.5-Air as the backend language model\n",
            "\n",
            "Example 1:\n",
            "Taste: flat illustration\n",
            "User Input:  A oversized engineer using magnifying glass doing inspection of building construction site under construction buildings signages equipment cranes, soft color palette, a poster by Tom Whalen, featured on behance, context art, behance hd, art on instagram, storybook illustration, Pro freelance, Illustration agency, Popular on Dribbble, soft shadows, no contrast, clean ultrasharp focus, premium vector, hand drawn people, timeless art, human illustration, freepik, flat colours, their faces are visible, show less details, clean lines and smooth curves, 2d flat illustration, contemporary art illustration, contemporary painting, use minimum props, limited Colors, use light grey color overlay for shadow, use light white color overlay for highlights, delicate art, whimsy and wonder, whimsical, by Alice Lee style, Wax crayon brushes procreate style, hand drawn \n",
            "\n",
            "DSPy-Optimized Prompt:\n",
            "Flat illustration of an oversized engineer inspecting a construction site with a magnifying glass, surrounded by buildings under construction, construction signages, and cranes. Clean lines and smooth curves with a soft, limited color palette. Light grey overlays create subtle shadows while light white overlays provide highlights. Whimsical and delicate hand-drawn elements inspired by Tom Whalen's bold stylization and Alice Lee's whimsical touch. Human illustration with visible faces, minimal props, and ultrasharp focus on the main subject. Contemporary 2d design with soft shadows and no harsh contrast, maintaining a timeless quality.\n",
            "\n",
            "Optimization Reasoning:\n",
            "1. The user input contains many repetitive and conflicting elements that need to be streamlined.\n",
            "2. The core subject is an oversized engineer inspecting a construction site with a magnifying glass.\n",
            "3. For flat illustration style, I need to focus on clean lines, minimal shadows, and flat colors while maintaining the whimsical elements mentioned.\n",
            "4. The user references multiple artists (Tom Whalen and Alice Lee) whose styles can be combined for the final prompt.\n",
            "5. Color specifications need to be consolidated into a cohesive \"soft color palette with limited colors\" approach.\n",
            "6. Technical aspects like \"ultrasharp focus\" and \"show less details\" need to be balanced for flat illustration.\n",
            "7. Redundant descriptors and platform references (Behance, Instagram, Dribbble) should be removed to focus on artistic elements.\n",
            "8. The prompt should flow logically from subject to environment to style and technique.\n",
            "\n",
            "DSPy-Enhanced Prompt (Final Output):\n",
            "Flat illustration of an oversized engineer in a yellow safety helmet and blue overalls inspecting a construction site through a large magnifying glass. The character has a friendly, curious expression with one eyebrow raised in concentration. The scene features mid-rise buildings under construction with visible scaffolding and unfinished facades. Surrounding elements include construction signages with safety warnings, colorful traffic cones, and towering cranes against a clear sky. The illustration employs clean lines with consistent 2pt line weight, utilizing a soft, limited color palette of muted blues, yellows, greys, and subtle earth tones. Light grey overlays (10% opacity) create subtle shadows, while light white overlays (5% opacity) provide highlights. Whimsical and delicate hand-drawn elements include stylized birds flying near the cranes and small flowers growing between construction materials, inspired by Tom Whalen's bold stylization and Alice Lee's whimsical touch. Human illustration with visible, friendly faces, minimal props, and ultrasharp focus on the main subject. The composition uses a slightly elevated 3/4 perspective to showcase the construction site. Contemporary 2D design with soft shadows, no harsh contrast, and a matte finish maintaining a timeless quality.\n",
            "\n",
            "Enhancement Reasoning:\n",
            "The base prompt is already well-structured for a flat illustration style, but I can enhance it by adding more technical details and artistic refinements to better align with the flat illustration taste. I'll focus on:\n",
            "\n",
            "1. Adding specific technical details about line weight and color application\n",
            "2. Enhancing the artistic style references with more precise descriptors\n",
            "3. Adding details about composition and perspective that work well with flat illustration\n",
            "4. Specifying texture and finish characteristics\n",
            "5. Adding details about the character's expression and posture to enhance storytelling\n",
            "6. Including more specific details about the environment to create a more vivid scene\n",
            "\n",
            "Quality Score: 0.40\n",
            "✅ SUCCESS: DSPy-optimized prompt generation completed!\n",
            "\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "qcz9WFMvBl2z",
        "outputId": "557a9a27-479d-4959-cf41-66481863ea1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:__main__:Could not import BootstrapFewShot from teleprompter module\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== DSPy-Optimized Image Prompt Generation System ===\n",
            "\n",
            "Using DSPy with:\n",
            "1. Defined signatures for initial optimization and enhancement\n",
            "2. Multi-stage pipeline (Initial Optimizer → Enhancer)\n",
            "3. Basic prompt optimization (teleprompter module not available)\n",
            "4. Quality-based metrics for evaluation\n",
            "5. GLM-4.5-Air as the backend language model\n",
            "\n",
            "Example 1:\n",
            "Taste: oil painting\n",
            "User Input: diwali greetings with text place holder, lantern, diya, indian festival\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1799688192.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1799688192.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;31m# Generate using DSPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             result = generator.generate(\n\u001b[0m\u001b[1;32m    306\u001b[0m                 \u001b[0mtaste\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'taste'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0muser_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user_input'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1799688192.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, taste, user_input)\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# Use the compiled DSPy optimizer or fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Running DSPy-optimized prompt generation...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaste\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtaste\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m             \u001b[0moptimized_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimized_prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/utils/callback.py\u001b[0m in \u001b[0;36msync_wrapper\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_active_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mcall_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/primitives/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1799688192.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, taste, user_input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# Step 2: Enhance the optimized prompt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         enhanced_result = self.enhancer(\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mbase_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimized_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimized_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mtaste\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtaste\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/utils/callback.py\u001b[0m in \u001b[0;36msync_wrapper\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_active_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mcall_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/primitives/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1799688192.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, base_prompt, taste)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_prompt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaste\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menhance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaste\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtaste\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mFullPromptOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdspy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/predict/predict.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_positional_args_error_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0macall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/utils/callback.py\u001b[0m in \u001b[0;36msync_wrapper\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_active_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mcall_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/primitives/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/predict/predict.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msend_stream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0mcompletions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdemos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/adapters/chat_adapter.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     ) -> list[dict[str, Any]]:\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlm_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;31m# fallback to JSONAdapter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/adapters/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, lm, lm_kwargs, signature, demos, inputs)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdemos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlm_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_postprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_signature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/utils/callback.py\u001b[0m in \u001b[0;36msync_wrapper\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_active_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mcall_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muuid4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/clients/base_lm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, messages, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwith_callbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_lm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/clients/lm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, prompt, messages, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mcompletion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlitellm_cache_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_cached_completion_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompletion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         results = completion(\n\u001b[0m\u001b[1;32m    148\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/clients/cache.py\u001b[0m in \u001b[0;36msync_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;31m# Make a copy of the original request in case it's modified in place, e.g., deleting some fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0moriginal_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodified_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m             \u001b[0;31m# `enable_memory_cache` can be provided at call time to avoid indefinite growth.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignored_args_for_cache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menable_memory_cache\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/dspy/clients/lm.py\u001b[0m in \u001b[0;36mlitellm_completion\u001b[0;34m(request, num_retries, cache)\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0mstream_completion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_stream_completion_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstream_completion\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m         return litellm.completion(\n\u001b[0m\u001b[1;32m    337\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0mnum_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/litellm/utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m                     \u001b[0mprint_verbose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error while checking max token limit: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m             \u001b[0;31m# MODEL CALL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moriginal_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1241\u001b[0m             \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m             if _is_streaming_request(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/litellm/main.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(model, messages, timeout, temperature, top_p, n, stream, stream_options, stop, max_completion_tokens, max_tokens, modalities, prediction, audio, presence_penalty, frequency_penalty, logit_bias, user, reasoning_effort, response_format, seed, tools, tool_choice, logprobs, top_logprobs, parallel_tool_calls, web_search_options, deployment_id, extra_headers, safety_identifier, service_tier, functions, function_call, base_url, api_version, api_key, model_list, thinking, shared_session, **kwargs)\u001b[0m\n\u001b[1;32m   2107\u001b[0m                     )\n\u001b[1;32m   2108\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2109\u001b[0;31m                     response = openai_chat_completions.completion(\n\u001b[0m\u001b[1;32m   2110\u001b[0m                         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m                         \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mcompletion\u001b[0;34m(self, model_response, timeout, optional_params, litellm_params, logging_obj, model, messages, print_verbose, api_key, api_base, api_version, dynamic_params, azure_ad_token, acompletion, logger_fn, headers, custom_prompt_dict, client, organization, custom_llm_provider, drop_params, shared_session)\u001b[0m\n\u001b[1;32m    671\u001b[0m                             \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m                             \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_sync_openai_chat_completion_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m                             \u001b[0mopenai_client\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopenai_client\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m                             \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/litellm/litellm_core_utils/logging_utils.py\u001b[0m in \u001b[0;36msync_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/litellm/llms/openai/openai.py\u001b[0m in \u001b[0;36mmake_sync_openai_chat_completion_request\u001b[0;34m(self, openai_client, data, timeout, logging_obj)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mraw_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             raw_response = openai_client.chat.completions.with_raw_response.create(\n\u001b[0m\u001b[1;32m    472\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_legacy_response.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"extra_headers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextra_headers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLegacyAPIResponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m   1146\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1147\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m   1148\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m                 response = self._client.send(\n\u001b[0m\u001b[1;32m    983\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m                     \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_stream_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    926\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m     def _send_handling_auth(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    879\u001b[0m         \"\"\"\n\u001b[1;32m    880\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_content\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 881\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    882\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_bytes\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    895\u001b[0m             \u001b[0mchunker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mByteChunker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mraw_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m                     \u001b[0mdecoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_models.py\u001b[0m in \u001b[0;36miter_raw\u001b[0;34m(self, chunk_size)\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mraw_stream_bytes\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_bytes_downloaded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_stream_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_client.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpx/_transports/default.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_httpcore_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_httpcore_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/connection_pool.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mpart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mpart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mShieldCancellation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"receive_response_body\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_response_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_response_body\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mevent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_receive_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mData\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_sync/http11.py\u001b[0m in \u001b[0;36m_receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mh11\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNEED_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 data = self._network_stream.read(\n\u001b[0m\u001b[1;32m    218\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mREAD_NUM_BYTES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/httpcore/_backends/sync.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmap_exceptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1230\u001b[0m                     \u001b[0;34m\"non-zero flags not allowed in calls to recv() on %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1231\u001b[0m                     self.__class__)\n\u001b[0;32m-> 1232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1233\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuflen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/ssl.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSSLError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSSL_ERROR_EOF\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import logging\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv('/content/.env')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Import required libraries\n",
        "import dspy\n",
        "from dspy import Example, Predict, ChainOfThought\n",
        "\n",
        "# API configuration\n",
        "API_KEY = os.getenv(\"OPENROUTER_API_KEY\") or \"\"\n",
        "MODEL = \"z-ai/glm-4.5-air:free\"\n",
        "TEMPERATURE = 0.7\n",
        "\n",
        "# Check if API key is available\n",
        "if not API_KEY:\n",
        "    raise ValueError(\"OPENROUTER_API_KEY not found in environment variables\")\n",
        "\n",
        "# Set up DSPy to use GLM via OpenRouter\n",
        "lm = dspy.LM(\n",
        "    model=\"openai/\" + MODEL,\n",
        "    api_key=API_KEY,\n",
        "    temperature=TEMPERATURE,\n",
        "    base_url=\"https://openrouter.ai/api/v1\"\n",
        ")\n",
        "dspy.settings.configure(lm=lm)\n",
        "logger.info(f\"Successfully configured DSPy with {MODEL}\")\n",
        "\n",
        "# Import validation functions\n",
        "def validate_taste(taste: str) -> str:\n",
        "    \"\"\"Validate the artistic taste category.\"\"\"\n",
        "    valid_tastes = ['photorealistic', 'oil painting', 'anime', 'cyberpunk', 'watercolor', '3d render']\n",
        "    if taste.lower() not in valid_tastes:\n",
        "        raise ValueError(f\"Invalid taste. Choose from: {', '.join(valid_tastes)}\")\n",
        "    return taste.lower()\n",
        "\n",
        "def validate_input(user_input: str) -> str:\n",
        "    \"\"\"Validate the user input description.\"\"\"\n",
        "    if not user_input or len(user_input.strip()) < 3:\n",
        "        raise ValueError(\"Please provide a description (at least 3 characters)\")\n",
        "    return user_input.strip()\n",
        "\n",
        "# Define DSPy signatures\n",
        "class InitialPromptOptimization(dspy.Signature):\n",
        "    \"\"\"Optimize user input into a detailed image prompt for the specified artistic style.\"\"\"\n",
        "    taste = dspy.InputField(desc=\"Artistic style (e.g., photorealistic, anime)\")\n",
        "    user_input = dspy.InputField(desc=\"Simple user description\")\n",
        "    optimized_prompt = dspy.OutputField(desc=\"Detailed optimized prompt\")\n",
        "\n",
        "class PromptEnhancement(dspy.Signature):\n",
        "    \"\"\"Enhance an optimized prompt with technical details and artistic refinements.\"\"\"\n",
        "    base_prompt = dspy.InputField(desc=\"Already optimized prompt\")\n",
        "    taste = dspy.InputField(desc=\"Artistic style\")\n",
        "    enhanced_prompt = dspy.OutputField(desc=\"Enhanced prompt with technical details and artistic refinements\")\n",
        "\n",
        "# Define DSPy modules\n",
        "class InitialPromptOptimizer(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.optimize = dspy.Predict(InitialPromptOptimization)\n",
        "\n",
        "    def forward(self, taste: str, user_input: str):\n",
        "        return self.optimize(taste=taste, user_input=user_input)\n",
        "\n",
        "class PromptEnhancer(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enhance = dspy.Predict(PromptEnhancement)\n",
        "\n",
        "    def forward(self, base_prompt: str, taste: str):\n",
        "        return self.enhance(base_prompt=base_prompt, taste=taste)\n",
        "\n",
        "class FullPromptOptimizer(dspy.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.initial_optimizer = InitialPromptOptimizer()\n",
        "        self.enhancer = PromptEnhancer()\n",
        "\n",
        "    def forward(self, taste: str, user_input: str):\n",
        "        # Step 1: Initial prompt optimization\n",
        "        optimized_result = self.initial_optimizer(taste=taste, user_input=user_input)\n",
        "\n",
        "        # Step 2: Enhance the optimized prompt\n",
        "        enhanced_result = self.enhancer(\n",
        "            base_prompt=optimized_result.optimized_prompt,\n",
        "            taste=taste\n",
        "        )\n",
        "\n",
        "        # Return the results as attributes of a simple object\n",
        "        class OptimizationResult:\n",
        "            def __init__(self, optimized_prompt, enhanced_prompt):\n",
        "                self.optimized_prompt = optimized_prompt\n",
        "                self.enhanced_prompt = enhanced_prompt\n",
        "\n",
        "        return OptimizationResult(\n",
        "            optimized_prompt=optimized_result.optimized_prompt,\n",
        "            enhanced_prompt=enhanced_result.enhanced_prompt\n",
        "        )\n",
        "\n",
        "# Prepare training data\n",
        "def create_training_data() -> List[Dict[str, str]]:\n",
        "    \"\"\"Create training examples for DSPy.\"\"\"\n",
        "    return [\n",
        "        {\n",
        "            'taste': 'photorealistic',\n",
        "            'user_input': 'a cat sitting on a windowsill',\n",
        "            'optimized_prompt': 'Ultra realistic photograph of a ginger cat sitting on a sunlit windowsill, detailed fur texture, sharp focus, natural lighting, 85mm lens, shallow depth of field',\n",
        "            'enhanced_prompt': 'Ultra realistic photograph of a ginger cat sitting on a sunlit windowsill, detailed fur texture, sharp focus, natural lighting, 85mm lens, shallow depth of field, 4K resolution, f/1.8 aperture, golden hour glow, cinematic composition'\n",
        "        },\n",
        "        {\n",
        "            'taste': 'oil painting',\n",
        "            'user_input': 'a mountain landscape',\n",
        "            'optimized_prompt': 'Oil painting of majestic mountain landscape at sunset, impressionist style, visible brushstrokes, warm golden hour light, textured canvas, rich color palette',\n",
        "            'enhanced_prompt': 'Oil painting of majestic mountain landscape at sunset, impressionist style, visible brushstrokes, warm golden hour light, textured canvas, rich color palette, canvas texture visible, Rembrandt lighting, thick impasto technique, 24\"x36\" aspect ratio'\n",
        "        },\n",
        "        {\n",
        "            'taste': 'anime',\n",
        "            'user_input': 'a futuristic city',\n",
        "            'optimized_prompt': 'Anime style illustration of a futuristic cyberpunk cityscape at night, neon lights, flying vehicles, detailed architecture, vibrant colors, high contrast',\n",
        "            'enhanced_prompt': 'Anime style illustration of a futuristic cyberpunk cityscape at night, neon lights, flying vehicles, detailed architecture, vibrant colors, high contrast, Studio Ghibli influences, detailed backgrounds, cel-shaded rendering, 1080p resolution'\n",
        "        },\n",
        "        {\n",
        "            'taste': 'cyberpunk',\n",
        "            'user_input': 'a street market',\n",
        "            'optimized_prompt': 'Cyberpunk street market at night, neon signs, diverse crowd, stalls selling futuristic tech, rain-slicked streets, Blade Runner aesthetic',\n",
        "            'enhanced_prompt': 'Cyberpunk street market at night, neon signs, diverse crowd, stalls selling futuristic tech, rain-slicked streets, Blade Runner aesthetic, cinematic lighting, volumetric fog, reflections on wet pavement, ultra-detailed, 8K resolution'\n",
        "        }\n",
        "    ]\n",
        "\n",
        "# Simple data container\n",
        "class TrainingData:\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "        return Example(\n",
        "            taste=item['taste'],\n",
        "            user_input=item['user_input'],\n",
        "            optimized_prompt=item['optimized_prompt'],\n",
        "            enhanced_prompt=item['enhanced_prompt']\n",
        "        ).with_inputs('taste', 'user_input')\n",
        "\n",
        "# Quality metric for DSPy evaluation\n",
        "def prompt_quality_metric(example, pred, trace=None) -> float:\n",
        "    \"\"\"Calculate quality score for the final enhanced prompt.\"\"\"\n",
        "    prompt = pred.enhanced_prompt\n",
        "\n",
        "    # Quality indicators\n",
        "    has_details = 'detailed' in prompt.lower()\n",
        "    has_style = any(style in prompt.lower() for style in ['style', 'technique', 'aesthetic'])\n",
        "    has_technical = any(tech in prompt.lower() for tech in ['lighting', 'focus', 'texture', 'composition', 'resolution', 'aperture'])\n",
        "    has_mood = any(mood in prompt.lower() for mood in ['mood', 'atmosphere', 'ambiance', 'feeling'])\n",
        "\n",
        "    # Check if it includes relevant technical details for the style\n",
        "    has_photography_terms = True\n",
        "    has_painting_terms = True\n",
        "\n",
        "    if example.taste == 'photorealistic':\n",
        "        has_photography_terms = any(term in prompt.lower() for term in ['aperture', 'f/', 'shutter', 'depth', 'bokeh'])\n",
        "    elif example.taste == 'oil painting':\n",
        "        has_painting_terms = any(term in prompt.lower() for term in ['brushstroke', 'impasto', 'canvas', 'palette', 'texture'])\n",
        "\n",
        "    # Calculate score\n",
        "    indicators = [has_details, has_style, has_technical, has_mood, has_photography_terms, has_painting_terms]\n",
        "    return sum(indicators) / len(indicators)\n",
        "\n",
        "# Main DSPy-powered prompt generator\n",
        "class DSPyPromptGenerator:\n",
        "    def __init__(self):\n",
        "        # Create training data\n",
        "        self.trainset = TrainingData(create_training_data())\n",
        "\n",
        "        # Initialize the full optimizer\n",
        "        self.optimizer = FullPromptOptimizer()\n",
        "\n",
        "        # Try to use BootstrapFewShot if available\n",
        "        try:\n",
        "            from dspy.teleprompter import BootstrapFewShot\n",
        "            teleprompter = BootstrapFewShot(metric=prompt_quality_metric)\n",
        "            self.compiled_optimizer = teleprompter.compile(self.optimizer, trainset=self.trainset)\n",
        "            logger.info(\"Using compiled optimizer with BootstrapFewShot\")\n",
        "        except ImportError:\n",
        "            try:\n",
        "                from dspy.teleprompters import BootstrapFewShot\n",
        "                teleprompter = BootstrapFewShot(metric=prompt_quality_metric)\n",
        "                self.compiled_optimizer = teleprompter.compile(self.optimizer, trainset=self.trainset)\n",
        "                logger.info(\"Using compiled optimizer with BootstrapFewShot\")\n",
        "            except ImportError:\n",
        "                logger.warning(\"Could not import BootstrapFewShot from teleprompter module\")\n",
        "                logger.info(\"Using non-compiled optimizer instead\")\n",
        "                self.compiled_optimizer = self.optimizer\n",
        "\n",
        "        self.results = []\n",
        "\n",
        "    def generate(self, taste: str, user_input: str) -> str:\n",
        "        \"\"\"Generate an enhanced image prompt using DSPy-optimized modules.\"\"\"\n",
        "        try:\n",
        "            # Validate inputs\n",
        "            taste = validate_taste(taste)\n",
        "            user_input = validate_input(user_input)\n",
        "            logger.info(f\"Validated input: {taste} - {user_input}\")\n",
        "\n",
        "            # Use the compiled DSPy optimizer or fallback\n",
        "            logger.info(\"Running DSPy-optimized prompt generation...\")\n",
        "            result = self.compiled_optimizer(taste=taste, user_input=user_input)\n",
        "\n",
        "            optimized_prompt = result.optimized_prompt\n",
        "            final_prompt = result.enhanced_prompt\n",
        "\n",
        "            # Calculate quality score\n",
        "            # Create a simple object with the enhanced prompt for the metric function\n",
        "            class SimplePrediction:\n",
        "                def __init__(self, enhanced_prompt):\n",
        "                    self.enhanced_prompt = enhanced_prompt\n",
        "\n",
        "            quality_score = prompt_quality_metric(\n",
        "                Example(taste=taste, user_input=user_input),\n",
        "                SimplePrediction(final_prompt)\n",
        "            )\n",
        "\n",
        "            # Store result\n",
        "            self.results.append({\n",
        "                'taste': taste,\n",
        "                'user_input': user_input,\n",
        "                'optimized_prompt': optimized_prompt,\n",
        "                'final_prompt': final_prompt,\n",
        "                'quality_score': quality_score\n",
        "            })\n",
        "\n",
        "            logger.info(f\"Generated prompt with quality score: {quality_score:.2f}\")\n",
        "            return final_prompt\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in prompt generation: {e}\")\n",
        "            fallback_prompt = f\"{taste} style image of {user_input}, detailed, high quality\"\n",
        "            logger.info(f\"Using fallback prompt: {fallback_prompt}\")\n",
        "\n",
        "            # Also store fallback result\n",
        "            self.results.append({\n",
        "                'taste': taste,\n",
        "                'user_input': user_input,\n",
        "                'optimized_prompt': fallback_prompt,\n",
        "                'final_prompt': fallback_prompt,\n",
        "                'quality_score': 0.0\n",
        "            })\n",
        "\n",
        "            return fallback_prompt\n",
        "\n",
        "    def get_results(self) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Get all generated results.\"\"\"\n",
        "        return self.results\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function using actual DSPy.\"\"\"\n",
        "    print(\"=== DSPy-Optimized Image Prompt Generation System ===\\n\")\n",
        "    print(\"Using DSPy with:\")\n",
        "    print(\"1. Defined signatures for initial optimization and enhancement\")\n",
        "    print(\"2. Multi-stage pipeline (Initial Optimizer → Enhancer)\")\n",
        "\n",
        "    try:\n",
        "        from dspy.teleprompter import BootstrapFewShot\n",
        "        print(\"3. BootstrapFewShot for automatic prompt optimization\")\n",
        "    except ImportError:\n",
        "        try:\n",
        "            from dspy.teleprompters import BootstrapFewShot\n",
        "            print(\"3. BootstrapFewShot for automatic prompt optimization\")\n",
        "        except ImportError:\n",
        "            print(\"3. Basic prompt optimization (teleprompter module not available)\")\n",
        "\n",
        "    print(\"4. Quality-based metrics for evaluation\")\n",
        "    print(f\"5. GLM-4.5-Air as the backend language model\\n\")\n",
        "\n",
        "    # Test examples\n",
        "    examples = [\n",
        "        {\n",
        "            \"taste\": \"oil painting\",\n",
        "            \"user_input\": \"diwali greetings with text place holder, lantern, diya, indian festival\"\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Initialize the DSPy prompt generator\n",
        "    generator = DSPyPromptGenerator()\n",
        "\n",
        "    for i, example in enumerate(examples, 1):\n",
        "        print(f\"Example {i}:\")\n",
        "        print(f\"Taste: {example['taste']}\")\n",
        "        print(f\"User Input: {example['user_input']}\")\n",
        "\n",
        "        try:\n",
        "            # Generate using DSPy\n",
        "            result = generator.generate(\n",
        "                taste=example['taste'],\n",
        "                user_input=example['user_input']\n",
        "            )\n",
        "\n",
        "            print(f\"\\nDSPy-Optimized Prompt:\")\n",
        "            print(f\"{generator.results[-1]['optimized_prompt']}\")\n",
        "\n",
        "            print(f\"\\nDSPy-Enhanced Prompt (Final Output):\")\n",
        "            print(f\"{result}\")\n",
        "\n",
        "            print(f\"\\nQuality Score: {generator.results[-1]['quality_score']:.2f}\")\n",
        "            print(\"✅ SUCCESS: DSPy-optimized prompt generation completed!\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ FAILED: {e}\\n\")\n",
        "\n",
        "        print(\"=\"*70)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "DSPy implementation for generating enhanced image generation prompts using GLM 4.5 Air\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import logging\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file if it exists\n",
        "load_dotenv()\n",
        "\n",
        "# Set environment variables directly (this will override .env if set above)\n",
        "os.environ['OPENROUTER_API_KEY'] = os.getenv('OPENROUTER_API_KEY', '')\n",
        "os.environ['MODEL'] = os.getenv('MODEL', 'z-ai/glm-4.5-air:free')\n",
        "os.environ['TEMPERATURE'] = os.getenv('TEMPERATURE', '0.3')\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Import required DSPy libraries\n",
        "import dspy\n",
        "from dspy import Example, Predict, ChainOfThought\n",
        "\n",
        "class DSPyImagePromptGenerator:\n",
        "    \"\"\"\n",
        "    Pure DSPy implementation for generating enhanced image generation prompts\n",
        "    Using GLM 4.5 Air model via OpenRouter\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: str = None, api_key: str = None, temperature: float = 0.3):\n",
        "        \"\"\"\n",
        "        Initialize DSPy image prompt generator with GLM 4.5 Air\n",
        "\n",
        "        Args:\n",
        "            model: Model name (will use GLM 4.5 Air by default)\n",
        "            api_key: API key for OpenRouter\n",
        "            temperature: Temperature setting\n",
        "        \"\"\"\n",
        "        self.model = model or os.getenv('MODEL', 'z-ai/glm-4.5-air:free')\n",
        "        self.api_key = api_key or os.getenv('OPENROUTER_API_KEY')\n",
        "        self.temperature = float(temperature or os.getenv('TEMPERATURE', 0.3))\n",
        "\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"OPENROUTER_API_KEY not found in environment variables. Please run Cell 2 to set it.\")\n",
        "\n",
        "        logger.info(f\"Initialized DSPy image prompt generator with model: {self.model}, temperature: {self.temperature}\")\n",
        "\n",
        "        # Configure DSPy with GLM 4.5 Air via OpenRouter\n",
        "        self.lm = dspy.LM(\n",
        "            model=\"openrouter/\" + self.model,  # Prefix with \"openrouter/\" for OpenRouter provider\n",
        "            api_key=self.api_key,\n",
        "            temperature=self.temperature,\n",
        "            base_url=\"https://openrouter.ai/api/v1\"\n",
        "        )\n",
        "        dspy.settings.configure(lm=self.lm)\n",
        "\n",
        "        # Create examples for few-shot learning\n",
        "        self.examples = [\n",
        "            Example(\n",
        "                taste=\"photorealistic\",\n",
        "                user_input=\"a cat sitting on a windowsill\",\n",
        "                enhanced_prompt=\"\"\"You are an expert image prompt engineer. Transform this image concept into a photorealistic AI image generation prompt.\n",
        "\n",
        "**Input**:\n",
        "- Image Concept: \"a cat sitting on a windowsill\"\n",
        "- Quality Style: \"photorealistic\"\n",
        "\n",
        "**Output**:\n",
        "Ultra realistic photograph of a ginger cat sitting on a sunlit windowsill, detailed fur texture with individual hairs visible, sharp focus on the subject's eyes, natural lighting with soft shadows, 85mm lens with shallow depth of field, visible dust particles in the light beam, detailed wood grain on the windowsill, warm color temperature\"\"\"\n",
        "            ),\n",
        "            Example(\n",
        "                taste=\"photorealistic\",\n",
        "                user_input=\"a mountain landscape at sunset\",\n",
        "                enhanced_prompt=\"\"\"You are an expert image prompt engineer. Transform this image concept into a photorealistic AI image generation prompt.\n",
        "\n",
        "**Input**:\n",
        "- Image Concept: \"a mountain landscape at sunset\"\n",
        "- Quality Style: \"photorealistic\"\n",
        "\n",
        "**Output**:\n",
        "Breathtaking photorealistic landscape of snow-capped mountains at golden hour, warm sunset colors reflecting on a serene lake, volumetric lighting with sun rays breaking through clouds, ultra high detail with visible rock textures and snow crystals, 8k resolution, deep depth of field with foreground elements to establish scale, atmospheric perspective on distant peaks\"\"\"\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Create a DSPy module for prompt enhancement\n",
        "        self.module = self.create_enhancement_module()\n",
        "\n",
        "    def create_enhancement_module(self):\n",
        "        \"\"\"Create a DSPy module for prompt enhancement\"\"\"\n",
        "        class PromptEnhancement(dspy.Module):\n",
        "            def __init__(self):\n",
        "                super().__init__()\n",
        "                self.enhance = ChainOfThought(\"taste, user_input -> enhanced_prompt\")\n",
        "\n",
        "            def forward(self, taste, user_input):\n",
        "                return self.enhance(taste=taste, user_input=user_input)\n",
        "\n",
        "        return PromptEnhancement()\n",
        "\n",
        "    def generate_prompt(self, taste: str, user_input: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate an enhanced image prompt using DSPy optimization\n",
        "\n",
        "        Args:\n",
        "            taste: Style/quality (e.g., \"photorealistic\")\n",
        "            user_input: Image description\n",
        "\n",
        "        Returns:\n",
        "            Enhanced image prompt string\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Generating enhanced prompt with taste: {taste}\")\n",
        "\n",
        "            # Format examples for the prompt\n",
        "            examples_text = \"\"\n",
        "            for example in self.examples:\n",
        "                examples_text += f\"Example:\\n\"\n",
        "                examples_text += f\"Taste: {example.taste}\\n\"\n",
        "                examples_text += f\"User Input: {example.user_input}\\n\"\n",
        "                examples_text += f\"Enhanced Prompt: {example.enhanced_prompt}\\n\\n\"\n",
        "\n",
        "            # Use the LM directly to avoid potential issues with module compilation\n",
        "            with dspy.settings.context(lm=self.lm):\n",
        "                # Create a prediction with the LM\n",
        "                pred = self.lm(\n",
        "                    prompt=f\"\"\"Generate an enhanced image generation prompt with the following details:\n",
        "\n",
        "Taste: {taste}\n",
        "User Input: {user_input}\n",
        "\n",
        "Examples:\n",
        "{examples_text}\n",
        "\n",
        "Generate a detailed, enhanced image prompt that captures the essence of the input with the specified style, following the structure and specifications from the examples.\"\"\"\n",
        "                )\n",
        "\n",
        "                # If the LM returns a string, use it directly\n",
        "                if isinstance(pred, str):\n",
        "                    enhanced_prompt = pred\n",
        "                else:\n",
        "                    # If the LM returns a more complex object, extract the text\n",
        "                    enhanced_prompt = str(pred)\n",
        "\n",
        "                logger.info(\"Enhanced prompt generated successfully\")\n",
        "                return enhanced_prompt.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating enhanced prompt: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test the prompt enhancement\n",
        "    print(\"🚀 Testing DSPy Image Prompt Enhancement with GLM 4.5 Air\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Initialize the prompt generator with GLM 4.5 Air\n",
        "        generator = DSPyImagePromptGenerator()\n",
        "        print(\"✅ DSPy image prompt generator initialized successfully\")\n",
        "\n",
        "        # Test with sample inputs\n",
        "        taste = \"photorealistic\"\n",
        "        user_input = \"a cat sitting on a windowsill\"\n",
        "\n",
        "        print(f\"\\n🔍 Testing with taste: {taste}\")\n",
        "        print(f\"User input: {user_input}\")\n",
        "\n",
        "        # Generate the enhanced prompt\n",
        "        enhanced_prompt = generator.generate_prompt(taste, user_input)\n",
        "        print(f\"\\n✅ Enhanced prompt generated successfully:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(enhanced_prompt)\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        print(\"\\n✅ Prompt enhancement test completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during testing: {str(e)}\")\n",
        "        logger.error(f\"Prompt enhancement test failed: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zCMhGpXSFnk",
        "outputId": "2fd5a716-6853-4e89-ea16-e29d6fde76f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Testing DSPy Image Prompt Enhancement with GLM 4.5 Air\n",
            "==================================================\n",
            "✅ DSPy image prompt generator initialized successfully\n",
            "\n",
            "🔍 Testing with taste: photorealistic\n",
            "User input: a cat sitting on a windowsill\n",
            "\n",
            "✅ Enhanced prompt generated successfully:\n",
            "==================================================\n",
            "['**Enhanced Prompt:**  \\nUltra realistic photograph of a sleek black cat perched on a weathered oak windowsill, intricate fur texture with individual hairs and subtle highlights visible, sharp focus on the subject\\'s piercing amber eyes, soft morning light casting gentle shadows across the scene, 85mm lens with shallow depth of field, visible dust motes dancing in the sunbeam, detailed wood grain and natural imperfections on the windowsill, warm golden hour color temperature, cinematic composition with blurred background foliage outside the window.  \\n\\n### Key Enhancements:  \\n1. **Specificity**: Added breed (\"sleek black cat\"), material (\"weathered oak windowsill\"), and time (\"morning light/golden hour\") for richer context.  \\n2. **Texture & Detail**: Emphasized \"individual hairs,\" \"wood grain,\" and \"natural imperfections\" for photorealism.  \\n3. **Lighting & Atmosphere**: Included \"dust motes dancing in the sunbeam\" and \"soft shadows\" to enhance realism and mood.  \\n4. **Technical Specs**: Maintained camera/lens details (\"85mm lens, shallow depth of field\") and color temperature (\"warm golden hour\").  \\n5. **Composition**: Added \"cinematic composition\" and \"blurred background foliage\" to guide depth and storytelling.  \\n\\nThis prompt balances technical precision with artistic flair, ensuring the AI generates a vivid, lifelike image while adhering to the photorealistic style.']\n",
            "==================================================\n",
            "\n",
            "✅ Prompt enhancement test completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Test with different inputs\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"\\n🎨 Testing with different image concepts\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Initialize generator\n",
        "    generator = DSPyImagePromptGenerator()\n",
        "\n",
        "    # Test with different inputs\n",
        "    test_cases = [\n",
        "        (\"photorealistic\", \"a civil engineer doing construction inspection at construction site\")\n",
        "    ]\n",
        "\n",
        "    for taste, user_input in test_cases:\n",
        "        print(f\"\\n🔍 Testing with taste: {taste}\")\n",
        "        print(f\"User input: {user_input}\")\n",
        "\n",
        "        try:\n",
        "            enhanced_prompt = generator.generate_prompt(taste, user_input)\n",
        "            print(f\"\\n✅ Enhanced prompt generated successfully:\")\n",
        "            print(\"=\" * 50)\n",
        "            print(enhanced_prompt)  # Changed: removed the [:500] truncation\n",
        "            print(\"=\" * 50)\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Error generating prompt: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZYAH65RSivd",
        "outputId": "f6e8d06b-7daf-476e-8393-22f44d65d929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🎨 Testing with different image concepts\n",
            "==================================================\n",
            "\n",
            "🔍 Testing with taste: photorealistic\n",
            "User input: a civil engineer doing construction inspection at construction site\n",
            "\n",
            "✅ Enhanced prompt generated successfully:\n",
            "==================================================\n",
            "['\\n### Enhanced Prompt for Image Generation:\\n\\n**Subject:** A photorealistic image of a **civil engineer** conducting a **construction inspection** at a **busy construction site**.  \\n\\n**Key Details:**  \\n- **Attire:** The engineer wears a **bright yellow safety vest**, a **hard hat**, and **steel-toed boots**, holding a **clipboard** and **digital tablet** for notes.  \\n- **Action:** The engineer is **gesturing toward structural elements** (e.g., rebar, concrete forms) while **reviewing blueprints** under natural daylight.  \\n- **Setting:** A **partially erected high-rise building** in the background, surrounded by **construction machinery** (excavators, cranes), **scaffolding**, and **stacks of building materials** (steel beams, concrete blocks).  \\n- **Atmosphere:** **Golden-hour lighting** (late afternoon sun casting long shadows), **slightly hazy** with dust particles visible in the air.  \\n- **Composition:** **Medium shot** focusing on the engineer, with **depth of field** blurring the chaotic background to emphasize professionalism.  \\n- **Style:** **Ultra-detailed, 8K resolution**, **cinematic lighting**, **realistic textures** (dusty concrete, reflective safety vest), and **lifelike human expressions** (focused, analytical).  \\n\\n**Full Prompt:**  \\n> *\"Photorealistic, ultra-detailed 8K image of a civil engineer in a yellow safety vest and hard hat, inspecting a construction site. The engineer holds a tablet and clipboard, gesturing toward rebar and concrete forms under golden-hour sunlight. Background: A partially built high-rise with cranes, scaffolding, and excavators. Dust particles haze the air, with shallow depth of field blurring the chaotic site. Cinematic lighting, realistic textures, and a focused, professional expression. Style: National Geographic photojournalism, sharp focus, lifelike details.\"*  \\n\\n### Why This Works:  \\n1. **Specificity:** Clearly defines the engineer’s attire, tools, and actions.  \\n2. **Environmental Context:** Includes construction site elements (machinery, materials) for authenticity.  \\n3. **Atmosphere & Lighting:** Golden-hour lighting and dust particles add realism and mood.  \\n4. **Technical Specs:** Mentions 8K resolution, depth of field, and textures to guide AI quality.  \\n5. **Style Reference:** \"National Geographic photojournalism\" ensures a documentary, photorealistic aesthetic.  \\n\\nThis prompt balances detail with artistic direction, ensuring the AI generates a vivid, professional scene aligned with the user’s vision.']\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "DSPy implementation for generating enhanced image generation prompts using GLM 4.5 Air\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import logging\n",
        "from typing import List, Dict, Any, Optional\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Set environment variables directly\n",
        "os.environ['OPENROUTER_API_KEY'] = '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'\n",
        "os.environ['MODEL'] = 'z-ai/glm-4.5-air:free'\n",
        "os.environ['TEMPERATURE'] = '0.3'\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO,\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
        ")\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Import required DSPy libraries\n",
        "import dspy\n",
        "from dspy import Example, Predict, ChainOfThought\n",
        "\n",
        "class DSPyImagePromptGenerator:\n",
        "    \"\"\"\n",
        "    Pure DSPy implementation for generating enhanced image generation prompts\n",
        "    Using GLM 4.5 Air model via OpenRouter\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: str = None, api_key: str = None, temperature: float = 0.3):\n",
        "        \"\"\"\n",
        "        Initialize DSPy image prompt generator with GLM 4.5 Air\n",
        "\n",
        "        Args:\n",
        "            model: Model name (will use GLM 4.5 Air by default)\n",
        "            api_key: API key for OpenRouter\n",
        "            temperature: Temperature setting\n",
        "        \"\"\"\n",
        "        self.model = model or os.getenv('MODEL', 'z-ai/glm-4.5-air:free')\n",
        "        self.api_key = api_key or os.getenv('OPENROUTER_API_KEY')\n",
        "        self.temperature = float(temperature or os.getenv('TEMPERATURE', 0.3))\n",
        "\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"OPENROUTER_API_KEY not found in environment variables\")\n",
        "\n",
        "        logger.info(f\"Initialized DSPy image prompt generator with model: {self.model}, temperature: {self.temperature}\")\n",
        "\n",
        "        # Configure DSPy with GLM 4.5 Air via OpenRouter\n",
        "        self.lm = dspy.LM(\n",
        "            model=\"openrouter/\" + self.model,  # Prefix with \"openrouter/\" for OpenRouter provider\n",
        "            api_key=self.api_key,\n",
        "            temperature=self.temperature,\n",
        "            base_url=\"https://openrouter.ai/api/v1\"\n",
        "        )\n",
        "        dspy.settings.configure(lm=self.lm)\n",
        "\n",
        "        # Create examples for few-shot learning\n",
        "        self.examples = [\n",
        "            Example(\n",
        "                taste=\"photorealistic\",\n",
        "                user_input=\"a cat sitting on a windowsill\",\n",
        "                enhanced_prompt=\"\"\"You are an expert image prompt engineer. Transform this image concept into a photorealistic AI image generation prompt.\n",
        "\n",
        "**Input**:\n",
        "- Image Concept: \"a cat sitting on a windowsill\"\n",
        "- Quality Style: \"photorealistic\"\n",
        "\n",
        "**Output**:\n",
        "Ultra realistic photograph of a ginger cat sitting on a sunlit windowsill, detailed fur texture with individual hairs visible, sharp focus on the subject's eyes, natural lighting with soft shadows, 85mm lens with shallow depth of field, visible dust particles in the light beam, detailed wood grain on the windowsill, warm color temperature, high dynamic range (HDR) for balanced exposure\"\"\"\n",
        "            ),\n",
        "            Example(\n",
        "                taste=\"photorealistic\",\n",
        "                user_input=\"a mountain landscape at sunset\",\n",
        "                enhanced_prompt=\"\"\"You are an expert image prompt engineer. Transform this image concept into a photorealistic AI image generation prompt.\n",
        "\n",
        "**Input**:\n",
        "- Image Concept: \"a mountain landscape at sunset\"\n",
        "- Quality Style: \"photorealistic\"\n",
        "\n",
        "**Output**:\n",
        "Breathtaking photorealistic landscape of snow-capped mountains at golden hour, warm sunset colors reflecting on a serene lake, volumetric lighting with sun rays breaking through clouds, ultra high detail with visible rock textures and snow crystals, 8k resolution, deep depth of field with foreground elements to establish scale, atmospheric perspective on distant peaks, natural color grading\"\"\"\n",
        "            ),\n",
        "            Example(\n",
        "                taste=\"photorealistic\",\n",
        "                user_input=\"a futuristic cityscape at night\",\n",
        "                enhanced_prompt=\"\"\"You are an expert image prompt engineer. Transform this image concept into a photorealistic AI image generation prompt.\n",
        "\n",
        "**Input**:\n",
        "- Image Concept: \"a futuristic cityscape at night\"\n",
        "- Quality Style: \"photorealistic\"\n",
        "\n",
        "**Output**:\n",
        "Hyperrealistic futuristic metropolis at night, towering neon-lit skyscrapers with detailed glass facades, flying vehicles with glowing headlights, holographic advertisements, detailed city reflections in rain-slicked streets, cinematic lighting with dramatic shadows, 8k resolution, deep depth of field, high dynamic range (HDR) for balanced exposure between bright neon and dark shadows\"\"\"\n",
        "            ),\n",
        "            Example(\n",
        "                taste=\"photorealistic\",\n",
        "                user_input=\"a close-up of a flower with dew drops\",\n",
        "                enhanced_prompt=\"\"\"You are an expert image prompt engineer. Transform this image concept into a photorealistic AI image generation prompt.\n",
        "\n",
        "**Input**:\n",
        "- Image Concept: \"a close-up of a flower with dew drops\"\n",
        "- Quality Style: \"photorealistic\"\n",
        "\n",
        "**Output**:\n",
        "Extreme close-up macro photograph of a vibrant flower with detailed dew drops, sharp focus on water droplets refracting light, visible pollen and intricate petal textures, shallow depth of field with blurred background, natural morning lighting with soft highlights, 100mm macro lens, high detail with visible water tension and refraction, natural color enhancement\"\"\"\n",
        "            ),\n",
        "            Example(\n",
        "                taste=\"photorealistic\",\n",
        "                user_input=\"a vintage car in a rainy street\",\n",
        "                enhanced_prompt=\"\"\"You are an expert image prompt engineer. Transform this image concept into a photorealistic AI image generation prompt.\n",
        "\n",
        "**Input**:\n",
        "- Image Concept: \"a vintage car in a rainy street\"\n",
        "- Quality Style: \"photorealistic\"\n",
        "\n",
        "**Output**:\n",
        "Vintage car parked on a wet cobblestone street at dusk, detailed chrome with water reflections on the body, shallow depth of field focusing on the car's emblem, raindrops visible on the windshield, cinematic lighting from streetlamps creating reflections on wet surfaces, 50mm lens with natural perspective, atmospheric mood with mist in the distance, high dynamic range for balanced exposure\"\"\"\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # Create a DSPy module for prompt enhancement\n",
        "        self.module = self.create_enhancement_module()\n",
        "\n",
        "    def create_enhancement_module(self):\n",
        "        \"\"\"Create a DSPy module for prompt enhancement\"\"\"\n",
        "        class PromptEnhancement(dspy.Module):\n",
        "            def __init__(self):\n",
        "                super().__init__()\n",
        "                self.enhance = ChainOfThought(\"taste, user_input -> enhanced_prompt\")\n",
        "\n",
        "            def forward(self, taste, user_input):\n",
        "                return self.enhance(taste=taste, user_input=user_input)\n",
        "\n",
        "        return PromptEnhancement()\n",
        "\n",
        "    def generate_prompt(self, taste: str, user_input: str) -> str:\n",
        "        \"\"\"\n",
        "        Generate an enhanced prompt using DSPy optimization\n",
        "\n",
        "        Args:\n",
        "            taste: Quality/style (e.g., \"photorealistic\")\n",
        "            user_input: Image description\n",
        "\n",
        "        Returns:\n",
        "            Enhanced prompt string\n",
        "        \"\"\"\n",
        "        try:\n",
        "            logger.info(f\"Generating enhanced prompt with taste: {taste}\")\n",
        "\n",
        "            # Use the LM directly to avoid potential issues with module compilation\n",
        "            with dspy.settings.context(lm=self.lm):\n",
        "                # Create a prediction with the LM\n",
        "                pred = self.lm(\n",
        "                    prompt=f\"\"\"Generate an enhanced prompt for an image generation with the following details:\n",
        "\n",
        "Taste: {taste}\n",
        "User Input: {user_input}\n",
        "\n",
        "Use the following examples as guidance for the structure and format of the enhanced prompt:\n",
        "\"\"\"\n",
        "                )\n",
        "\n",
        "                # If the LM returns a string, use it directly\n",
        "                if isinstance(pred, str):\n",
        "                    enhanced_prompt = pred\n",
        "                else:\n",
        "                    # If the LM returns a more complex object, extract the text\n",
        "                    enhanced_prompt = str(pred)\n",
        "\n",
        "                logger.info(\"Enhanced prompt generated successfully\")\n",
        "                return enhanced_prompt.strip()\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating enhanced prompt: {str(e)}\")\n",
        "            raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Test the prompt enhancement\n",
        "    print(\"🚀 Testing DSPy Image Prompt Enhancement with GLM 4.5 Air\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Initialize the prompt generator with GLM 4.5 Air\n",
        "        generator = DSPyImagePromptGenerator()\n",
        "        print(\"✅ DSPy image prompt generator initialized successfully\")\n",
        "\n",
        "        # Test with sample inputs\n",
        "        taste = \"photorealistic\"\n",
        "        user_input = \"aerial view of paragliding about to crash near land\"\n",
        "\n",
        "        print(f\"\\n🔍 Testing with taste: {taste}\")\n",
        "        print(f\"User input: {user_input}\")\n",
        "\n",
        "        # Generate the enhanced prompt\n",
        "        enhanced_prompt = generator.generate_prompt(taste, user_input)\n",
        "        print(f\"\\n✅ Enhanced prompt generated successfully:\")\n",
        "        print(\"=\" * 50)\n",
        "        print(enhanced_prompt)\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "        print(\"\\n✅ Prompt enhancement test completed successfully!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error during testing: {str(e)}\")\n",
        "        logger.error(f\"Prompt enhancement test failed: {str(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YiuSihhkXq__",
        "outputId": "094bb2a9-4aea-46cb-ba41-c96fe909b747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Testing DSPy Image Prompt Enhancement with GLM 4.5 Air\n",
            "==================================================\n",
            "✅ DSPy image prompt generator initialized successfully\n",
            "\n",
            "🔍 Testing with taste: photorealistic\n",
            "User input: aerial view of paragliding about to crash near land\n",
            "\n",
            "✅ Enhanced prompt generated successfully:\n",
            "==================================================\n",
            "['Here\\'s an enhanced prompt incorporating photorealistic details and dramatic tension, following best practices for image generation:\\n\\n**Enhanced Prompt:**  \\n\"Ultra-detailed aerial drone perspective of a paraglider in a catastrophic descent, wing canopy violently collapsing and twisted mid-air, pilot\\'s harness straining against gravity, trajectory aimed directly at jagged coastal rocks just 20 feet below. Dynamic motion blur on the canopy lines, intense late-afternoon sun casting long shadows across the shoreline, turbulent wind whipping up sea spray. Shot on Sony A7R IV with 200mm telephoto lens, f/2.8 aperture, shallow depth of field, hyperrealistic textures on nylon fabric and wet rocks, cinematic color grading with desaturated blues and fiery orange highlights, sense of imminent impact and visceral danger. 8K resolution, Unreal Engine 5 rendering, photorealistic subsurface scattering on skin and fabric.\"\\n\\n---\\n\\n### Key Enhancements Explained:\\n1. **Specific Camera & Technical Specs**  \\n   - Camera model (Sony A7R IV), lens (200mm telephoto), aperture (f/2.8) for realistic depth of field and compression.  \\n   - \"Drone perspective\" clarifies the aerial viewpoint.\\n\\n2. **Dynamic Action & Physics**  \\n   - \"Violently collapsing,\" \"twisted mid-air,\" \"trajectory aimed directly\" emphasize the crash scenario.  \\n   - \"Motion blur on canopy lines\" and \"turbulent wind\" add kinetic energy.\\n\\n3. **Environmental Storytelling**  \\n   - \"Jagged coastal rocks,\" \"sea spray,\" and \"late-afternoon sun\" create a high-stakes coastal setting.  \\n   - \"Long shadows\" and \"fiery orange highlights\" enhance dramatic lighting.\\n\\n4. **Material Realism**  \\n   - \"Hyperrealistic textures on nylon fabric and wet rocks,\" \"subsurface scattering on skin\" for photorealistic materials.  \\n   - \"Cinematic color grading\" with desaturated blues/oranges for mood.\\n\\n5. **Artistic Direction**  \\n   - \"Imminent impact and visceral danger\" reinforces the tension.  \\n   - \"Unreal Engine 5 rendering\" and \"8K resolution\" ensure cutting-edge quality.\\n\\n6. **Safety & Ethics Note**  \\n   - The prompt depicts a *simulated* crash scenario for artistic purposes, avoiding glorification of real danger.\\n\\nThis structure balances technical precision with emotional storytelling, ensuring the AI generates a compelling, photorealistic image that matches the user’s input while elevating it with cinematic detail.']\n",
            "==================================================\n",
            "\n",
            "✅ Prompt enhancement test completed successfully!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}